{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has a **metrics/precision(B) of 80%**.\n",
    "\n",
    "*Metrics/precision(B) represents the proportion of true positive predictions among all positive predictions made by the model on the validation dataset, indicating how accurately the model identifies relevant objects without including false positives.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Pretrained YOLOv8 using image training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "New https://pypi.org/project/ultralytics/8.2.78 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.6 torch-2.4.0 CPU (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/data.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n",
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3012213 parameters, 3012197 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/labels... 6568 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6568/6568 [00:03<00:00, 1824.39it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Twalv0327_jpg.rf.478c8d4a41e56259c953c5d4eaa9419c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Twalv0327_jpg.rf.4a96e2336d780f808ca0115dc58f7e01.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Twalv0327_jpg.rf.55ae9a1ac881739e15d8055f7f2446b2.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video1_201_jpg.rf.0f2098c0306c0be3a5b5aab3641864e4.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video1_207_jpg.rf.2cbf4ea23f3f6693eaf7e25719c28fc2.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video1_207_jpg.rf.58490e6532f3d0f3be514d162a055e92.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video1_223_jpg.rf.665696b94c6a6f6a62956aea15842fd7.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video1_223_jpg.rf.d06b80e9fa48f7f9f85a46985b21277f.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video1_223_jpg.rf.f1ad06030a55e0dfc46cf991efd0ef2c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video1_26_jpg.rf.178bf5fec8eb69e56aba156c073729cd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video1_26_jpg.rf.8240bfa0dc1c4181b450c6c2f4dc5738.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video1_26_jpg.rf.efa98669f5ac6f64103d64375b494ced.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video2_167_jpg.rf.3da51cf0b2af0de8567e8e73590d6dd6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video3_113_jpg.rf.329577e6e71d3bb395fbb7e5ca7b2a27.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video3_113_jpg.rf.521313f7184b12eeac64819077f4669d.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/images/Video3_113_jpg.rf.f27c5f3a01266098580d6184b65ef976.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/labels... 1892 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1892/1892 [00:00<00:00, 1906.81it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video1_201_jpg.rf.569a5654ff46d94cb7c9ad03e15646f1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video1_207_jpg.rf.b30311695fc05cee446ca3a5efbc7cc8.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video2_167_jpg.rf.06d5b41a3a9c8bf356d419890fd01970.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video2_167_jpg.rf.1533196800c71cba2fab962a167d3174.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video2_19_jpg.rf.823c7c2fa3e3ad41c10d73325f35723e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video2_19_jpg.rf.9c8f141f53ab804e46d3a28c2587439a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video2_19_jpg.rf.e2423e578732e34a193aae59467f67f5.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/labels.cache\n",
      "Plotting labels to runs/detect/train5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3         0G       1.37      1.844      1.417        207        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 411/411 [1:34:36<00:00, 13.81s/it]   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [05:56<00:00,  5.95s/it]\n",
      "                   all       1892      21540      0.751      0.657      0.708      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3         0G      1.221      1.127      1.315         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 411/411 [46:15<00:00,  6.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [05:04<00:00,  5.08s/it]\n",
      "                   all       1892      21540      0.752      0.717      0.761      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3         0G      1.146     0.9885      1.268        108        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 411/411 [46:08<00:00,  6.74s/it]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [05:05<00:00,  5.09s/it]\n",
      "                   all       1892      21540      0.803      0.763      0.812      0.542\n",
      "\n",
      "3 epochs completed in 3.387 hours.\n",
      "Optimizer stripped from runs/detect/train5/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train5/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train5/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.6 torch-2.4.0 CPU (Apple M1 Pro)\n",
      "Model summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [04:37<00:00,  4.63s/it]\n",
      "                   all       1892      21540      0.803      0.763      0.812      0.542\n",
      "                Gloves       1892       4653      0.817      0.778      0.838      0.514\n",
      "                Helmet       1892       2388      0.892      0.867      0.917      0.598\n",
      "            Non-Helmet       1892        620      0.774      0.625      0.747      0.474\n",
      "                Person       1892       5254      0.864      0.916      0.935      0.709\n",
      "                 Shoes       1892       3426      0.887      0.865      0.912       0.61\n",
      "                  Vest       1892       4616      0.862      0.899       0.94      0.702\n",
      "             bare-arms       1892        583      0.527      0.391      0.393      0.191\n",
      "Speed: 1.2ms preprocess, 139.9ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "results = model.train(data=f'safety-rd-v1/data.yaml', epochs=3, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.6 torch-2.4.0 CPU (Apple M1 Pro)\n",
      "Model summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/labels.cache... 1892 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1892/1892 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video1_201_jpg.rf.569a5654ff46d94cb7c9ad03e15646f1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video1_207_jpg.rf.b30311695fc05cee446ca3a5efbc7cc8.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video2_167_jpg.rf.06d5b41a3a9c8bf356d419890fd01970.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video2_167_jpg.rf.1533196800c71cba2fab962a167d3174.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video2_19_jpg.rf.823c7c2fa3e3ad41c10d73325f35723e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video2_19_jpg.rf.9c8f141f53ab804e46d3a28c2587439a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/valid/images/Video2_19_jpg.rf.e2423e578732e34a193aae59467f67f5.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119/119 [05:38<00:00,  2.85s/it]\n",
      "                   all       1892      21540      0.803      0.763      0.812      0.542\n",
      "                Gloves       1892       4653      0.817      0.778      0.838      0.514\n",
      "                Helmet       1892       2388      0.892      0.867      0.917      0.598\n",
      "            Non-Helmet       1892        620      0.774      0.625      0.747      0.474\n",
      "                Person       1892       5254      0.864      0.916      0.935      0.709\n",
      "                 Shoes       1892       3426      0.887      0.865      0.912       0.61\n",
      "                  Vest       1892       4616      0.862      0.899       0.94      0.702\n",
      "             bare-arms       1892        583      0.527      0.391      0.393      0.191\n",
      "Speed: 0.6ms preprocess, 172.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=f'safety-rd-v1/data.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.6 torch-2.4.0 CPU (Apple M1 Pro)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train5/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 11, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.4.0...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 1.4s, saved as 'runs/detect/train5/weights/best.torchscript' (11.9 MB)\n",
      "\n",
      "Export complete (2.4s)\n",
      "Results saved to \u001b[1m/Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/runs/detect/train5/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs/detect/train5/weights/best.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs/detect/train5/weights/best.torchscript imgsz=640 data=/Users/HeberdenN21/Documents/2024 University/Semester-2/SOFT3888/YOLOv8-Practice/safety-RD-v1-1/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/detect/train5/weights/best.torchscript'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
